{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "from models import *\n",
    "from data_processing import *\n",
    "from method import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_API_KEY\"] = \"\" # YOUR KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\" # YOUR KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GET MODEL ###\n",
    "\n",
    "# model_type = \"openai\"; model_name = \"gpt-4-turbo-preview\"\n",
    "# model_type = \"google\"; model_name = \"gemini-pro\"\n",
    "# model_type = \"huggingface\"; model_name = \"meta-llama/Llama-2-70b-chat-hf\"\n",
    "model_type = \"openai\" \n",
    "model_name = \"gpt-4-turbo-preview\"\n",
    "model = llm_function(model_type, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Huggingface TASKS ###\n",
    "\n",
    "# huggingface_task_name = \"gsm8k\"\n",
    "# correct_answers = 0\n",
    "# tasks, answers = get_huggingface_dataset(huggingface_task_name)\n",
    "# for i in range(len(tasks)):\n",
    "    # inp = tasks[i]\n",
    "    # correct_out = answers[i]\n",
    "    # out = SGE(inp, model)\n",
    "    # solution = numeric_answer_extractor(correct_out)\n",
    "    # if str(solution) in out:\n",
    "        # correct_answers += 1\n",
    "# performance = correct_answers / len(tasks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CP TASKS ###\n",
    "\n",
    "or_task_name = \"vrp\"\n",
    "max_interval = 100\n",
    "num_instances = 1\n",
    "gaps = []\n",
    "\n",
    "for _ in range(num_instances):\n",
    "    if or_task_name == \"assignment\":\n",
    "        num_workers = 5\n",
    "        or_task_obj = Assignment(max_interval, num_workers)\n",
    "    elif or_task_name == \"knapsack\":\n",
    "        num_items = 10\n",
    "        capacities = 500\n",
    "        or_task_obj = Knapsack(max_interval, num_items, capacities)\n",
    "    elif or_task_name == \"bin_packing\":\n",
    "        num_items = 10\n",
    "        bin_capacity = 5\n",
    "        or_task_obj = BinPacking(max_interval, num_cities, num_vehicles)\n",
    "    elif or_task_name == \"tsp\":\n",
    "        num_cities = 10\n",
    "        num_vehicles = 1\n",
    "        or_task_obj = VRP(max_interval, num_cities, num_vehicles)\n",
    "    elif or_task_name == \"vrp\":\n",
    "        num_cities = 10\n",
    "        num_vehicles = 3\n",
    "        or_task_obj = VRP(max_interval, num_cities, num_vehicles)\n",
    "    elif or_task_name == \"jsp\":\n",
    "        num_cities = 10\n",
    "        num_vehicles = 3\n",
    "        or_task_obj = JSP(max_interval, num_cities, num_vehicles)\n",
    "\n",
    "    or_task_obj.get_variables()\n",
    "    optimal_solution, optimal_cost = or_task_obj.solve()\n",
    "    inp = or_task_obj.create_prompt()\n",
    "    out = SGE(inp, model)\n",
    "\n",
    "    solution = get_cp_solution(out)\n",
    "    model_cost = or_task_obj.compute_cost(solution)\n",
    "    gap = get_gap(model_cost, optimal_cost)\n",
    "    gaps.append(gap)\n",
    "\n",
    "performance = sum(gaps)/len(gaps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kcl_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
