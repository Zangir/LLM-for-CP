{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6d67b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70424fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks1 = ['AQUA', 'GSM8K', 'SVAMP', 'ASDiv', 'StrategyQA', 'CSQA', 'ARC', 'LastLetter']\n",
    "models = ['gpt3.5', 'gpt4', 'gemini', 'llama7', 'llama70']\n",
    "methods = ['io', 'cot', 'refine', 'decomp', 'ours', 'optimal']\n",
    "sizes = [5,8,12,15,20,25,30]\n",
    "tasks = ['assign', 'knapsack', 'bin-pack', 'tsp', 'vrp', 'jsp']\n",
    "tasks_full = ['Assignment', 'Knapsack', 'Bin Packing', 'Travelling Salesman', 'Vehicle Routing', 'Job Scheduling']\n",
    "\n",
    "results = pd.read_csv('results/results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a2c5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 1\n",
    "i = 0\n",
    "for task in tasks:\n",
    "    row = tasks_full[i]\n",
    "    i += 1\n",
    "    for model in ('gpt4', 'gemini'):\n",
    "        base_results = results.loc[results[\"Task\"] == task]\n",
    "        base_results = base_results.loc[base_results[\"Model\"] == model]\n",
    "        \n",
    "        io_results = base_results.loc[base_results[\"Method\"] == 'io'].sort_values('Size')['Cost'].values\n",
    "\n",
    "        for method in ('cot', 'refine', 'decomp', 'ours'):\n",
    "            subresults = base_results.loc[base_results[\"Method\"] == method].sort_values('Size')['Cost'].values\n",
    "            \n",
    "            imrovement = abs(subresults - io_results) / subresults\n",
    "            imrovement = 100*imrovement.mean()\n",
    "            imrovement = round(imrovement, 2)\n",
    "            if imrovement >= 100:\n",
    "                imrovement = round(imrovement, 1)\n",
    "\n",
    "            str_imrovement = str(imrovement)\n",
    "            while len(str_imrovement) < 5:\n",
    "                str_imrovement += '0'\n",
    "            if method == 'ours':\n",
    "                row += ' & \\\\textbf{' + str(str_imrovement) + '}'\n",
    "            else:\n",
    "                row += ' & ' + str(str_imrovement)\n",
    "    row += \" \\\\\\ \"\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1713448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 2\n",
    "for size in sizes:\n",
    "    row = str(size)\n",
    "    for task in tasks:\n",
    "        base_results = results.loc[results[\"Size\"] == size]\n",
    "        base_results = base_results.loc[base_results[\"Task\"] == task]\n",
    "        base_results = base_results.loc[base_results[\"Model\"] == 'gpt4']\n",
    "        \n",
    "        io_results = base_results.loc[base_results[\"Method\"] == 'io']\n",
    "        io_results_mean = io_results['Cost'].values\n",
    "        \n",
    "        subresults = base_results.loc[base_results[\"Method\"] == 'ours']\n",
    "        subresults_mean = subresults['Cost'].values\n",
    "        \n",
    "        imrovement = abs(subresults_mean - io_results_mean)/subresults_mean\n",
    "        imrovement = round(100*imrovement.mean(), 2)\n",
    "        if imrovement >= 100:\n",
    "            imrovement = round(imrovement, 1)\n",
    "\n",
    "        str_imrovement = str(imrovement)\n",
    "        while len(str_imrovement) < 5:\n",
    "            str_imrovement += '0'\n",
    "        row += ' & ' + str(str_imrovement)\n",
    "    row += \" \\\\\\ \"\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51d8832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 3\n",
    "method_full = ['IO', 'CoT', 'Refine', 'Decomp', 'Ours']\n",
    "for size in (5,8,12):\n",
    "    i = 0\n",
    "    for method in ('io', 'cot', 'refine', 'decomp', 'ours'):\n",
    "        row = \"& \" + method_full[i]\n",
    "        i += 1\n",
    "        for task in tasks:\n",
    "            base_results = results.loc[results[\"Size\"] == size]            \n",
    "            base_results = base_results.loc[base_results[\"Task\"] == task]\n",
    "\n",
    "            optimal_results = base_results.loc[base_results[\"Method\"] == 'optimal']\n",
    "            optimal_results_mean = optimal_results['Cost'].values\n",
    "            \n",
    "            subresults = base_results.loc[base_results[\"Model\"] == 'gpt4']\n",
    "            subresults = subresults.loc[subresults[\"Method\"] == method]\n",
    "            subresults_mean = subresults['Cost'].values\n",
    "            \n",
    "            imrovement = abs(subresults_mean - optimal_results_mean)/optimal_results_mean\n",
    "            imrovement = round(100*imrovement.mean(), 2)\n",
    "            if imrovement >= 100:\n",
    "                imrovement = round(imrovement, 1)\n",
    "\n",
    "            str_imrovement = str(imrovement)\n",
    "            while len(str_imrovement) < 5:\n",
    "                str_imrovement += '0'\n",
    "            if method == 'ours':\n",
    "                row += ' & \\\\textbf{' + str(str_imrovement) + '}'\n",
    "            else:\n",
    "                row += ' & ' + str(str_imrovement)\n",
    "        row += \" \\\\\\ \"\n",
    "        print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6f799b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 4\n",
    "i = 0\n",
    "for task in tasks:\n",
    "    row = tasks_full[i]\n",
    "    i += 1\n",
    "    for model in models:         \n",
    "        base_results = results.loc[results[\"Task\"] == task]\n",
    "        base_results = base_results.loc[base_results[\"Model\"] == model]\n",
    "\n",
    "        io_results = base_results.loc[base_results[\"Method\"] == 'io']\n",
    "        io_results_mean = io_results['Cost'].values\n",
    "\n",
    "        subresults = base_results.loc[base_results[\"Method\"] == 'ours']\n",
    "        subresults_mean = subresults['Cost'].values\n",
    "\n",
    "        imrovement = 100*abs(subresults_mean - io_results_mean)/subresults_mean\n",
    "        imrovement = round(imrovement.mean(), 2)\n",
    "        if imrovement >= 100:\n",
    "            imrovement = round(imrovement, 1)\n",
    "            \n",
    "        str_imrovement = str(imrovement)\n",
    "        while len(str_imrovement) < 5:\n",
    "            str_imrovement += '0'\n",
    "        row += ' & ' + str(str_imrovement)\n",
    "    row += \" \\\\\\ \"\n",
    "    print(row)\n",
    "# Big Tables for each model from plots_n_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a303e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 6\n",
    "\n",
    "for model in ['gpt4']:\n",
    "    base_results = results.loc[results[\"Model\"] == model]\n",
    "    io_results = base_results.loc[base_results[\"Method\"] == 'io']['Cost'].values\n",
    "\n",
    "    for method in ('cot', 'refine', 'decomp', 'ours'):\n",
    "        subresults = base_results.loc[base_results[\"Method\"] == method]['Cost'].values\n",
    "        \n",
    "        imrovement = abs(subresults - io_results) / subresults\n",
    "        imrovement = 100*imrovement.mean()\n",
    "        imrovement = round(imrovement, 2)\n",
    "        if imrovement >= 100:\n",
    "            imrovement = round(imrovement, 1)\n",
    "        print(method, imrovement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35ddfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big Tables\n",
    "str_sizes = [str(size) for size in sizes]\n",
    "for i1 in range(len(models)):\n",
    "    model = models[i1]\n",
    "\n",
    "    print()\n",
    "    print(model)\n",
    "\n",
    "    sub_table = results.loc[results['Model'] == model]\n",
    "    sub_table = sub_table.loc[sub_table['Task'].isin(tasks)]\n",
    "    sub_table = sub_table.loc[sub_table['Method'].isin(methods[:-1])]\n",
    "    sub_table = sub_table[['Method', 'Size', 'Task', 'Cost']]\n",
    "    sub_table = sub_table.pivot_table(index=['Method', 'Size'], columns='Task', values='Cost', aggfunc='mean') \n",
    "    sub_table = sub_table.reset_index()\n",
    "    avg = sub_table.drop('Method', axis=1).groupby(['Size']).mean().reset_index()\n",
    "    avg['Method'] = 'Avg.'\n",
    "    sub_table = pd.concat([sub_table, avg], ignore_index=True)\n",
    "    sub_table = sub_table.round(2)\n",
    "    sub_table['Size'] = sub_table['Size'].astype(int).astype(str)\n",
    "    new_method_rows = {\n",
    "        'Avg.' : 'Avg.',\n",
    "        'io' : \"IO\", \n",
    "        'cot' : \"CoT\", \n",
    "        'refine' : \"Refine\", \n",
    "        'decomp' : \"Decomp\", \n",
    "        'ours' : \"Ours\"\n",
    "    }\n",
    "\n",
    "    sub_table['Method'] = sub_table['Method'].map(new_method_rows)\n",
    "    sub_table_copy = sub_table.copy()\n",
    "\n",
    "    for size in sizes:\n",
    "        sub_table = sub_table_copy.loc[sub_table_copy['Size'] == str(size)]\n",
    "        sub_table = sub_table.groupby(['Size', 'Method']).mean()\n",
    "        indices = pd.MultiIndex.from_product([str_sizes, \n",
    "            list(new_method_rows.values())], names=['Size', 'Method'])\n",
    "        sub_table = sub_table.reindex(indices)\n",
    "        \n",
    "        bold_values = sub_table.min(axis=0)\n",
    "        sub_table = sub_table[tasks]\n",
    "        sub_table.reset_index(inplace=True)\n",
    "        sub_table = sub_table.dropna().reset_index(drop=True)\n",
    "        del sub_table['Size']\n",
    "\n",
    "        # get string for latex\n",
    "        latex_row = \"\\\\multirow{6}{*}{\\\\begin{sideways}\\\\method{\\\\normalsize \" + str(size) + \" nodes}\\\\end{sideways}} & \"\n",
    "        print(latex_row)\n",
    "        for i in range(len(sub_table)):\n",
    "            latex_row = \"\"\n",
    "            for column in sub_table.columns:\n",
    "                if i == 0:\n",
    "                    latex_row += \"\\cellcolor{gray!25} \"\n",
    "                value = sub_table.at[i, column]\n",
    "                if column != 'Method':\n",
    "                    value = float(value)\n",
    "                    if value < 10:\n",
    "                        value = round(value, 5)\n",
    "                    elif value < 100:\n",
    "                        value = round(value, 4)\n",
    "                    elif value < 1000:\n",
    "                        value = round(value, 3)\n",
    "                    elif value < 10000:\n",
    "                        value = round(value, 2)\n",
    "                    elif value < 100000:\n",
    "                        value = round(value, 1)\n",
    "                    else:\n",
    "                        value = round(value, 0)\n",
    "                str_value = str(value)\n",
    "                if column != 'Method':\n",
    "                    while len(str_value) < 6:\n",
    "                        str_value += '0'\n",
    "                elif i != 0:\n",
    "                    latex_row += \"& \"\n",
    "                if column in bold_values and i == len(sub_table)-1:\n",
    "                    latex_row += \"\\\\textbf{\" + str_value + \"} & \"\n",
    "                else:\n",
    "                    latex_row += str_value + \" & \"\n",
    "\n",
    "            latex_row = latex_row[:-3] + \" \\\\\\\\ \"\n",
    "            print(latex_row)\n",
    "        print(\" \\\\hline \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f801911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 5\n",
    "\n",
    "for i1 in range(len(models)):\n",
    "    model = models[i1]\n",
    "    # if model != 'gpt-3.5':\n",
    "    #     continue\n",
    "    if model != 'gpt-4':\n",
    "        continue\n",
    "    sub_table = results.loc[results['Model'] == model]\n",
    "    sub_table = sub_table.loc[sub_table['Task'].isin(tasks1)]\n",
    "    sub_table = sub_table.loc[sub_table['Shot'].isin([np.NAN, '5', 'None'])]\n",
    "    sub_table = sub_table[['Task', 'Method', 'Value']]\n",
    "    sub_table = sub_table.pivot_table(index='Method', columns='Task', values='Value', aggfunc='mean')\n",
    "    sub_table = sub_table.reindex(methods[:-1])  \n",
    "    # get average | max values\n",
    "    sub_table['Avg'] = sub_table.mean(axis=1)\n",
    "    sub_table = sub_table.round(2)\n",
    "    bold_values = sub_table.max(axis=0)\n",
    "    # reorder rows | cols\n",
    "    sub_table.reset_index(inplace=True)\n",
    "    new_task_columns = ['Method'] + tasks1 + ['Avg']\n",
    "    sub_table = sub_table[new_task_columns]\n",
    "    new_method_rows = ['IO Prompting', 'CoT Prompting', 'Refine Prompting', 'Decomp Prompting', 'Ours']\n",
    "    sub_table['Method'] = new_method_rows\n",
    "    sub_table = sub_table.dropna().reset_index(drop=True)\n",
    "    # get string for latex\n",
    "    for i in range(len(sub_table)):\n",
    "        latex_row = \"\"\n",
    "        for column in sub_table.columns:\n",
    "            str_value = str(sub_table.at[i, column])\n",
    "            while len(str_value) < 5:\n",
    "                str_value += '0'\n",
    "            if column in bold_values and sub_table.at[i, column] == bold_values[column]:\n",
    "                latex_row += \"\\\\textbf{\" + str_value + \"} & \"\n",
    "            else:\n",
    "                latex_row += str_value + \" & \"\n",
    "        latex_row = latex_row[:-3] + \" \\\\\\\\\"\n",
    "        print(latex_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60246aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2\n",
    "data = {}\n",
    "for size in sizes:\n",
    "    if size == 25:\n",
    "        break\n",
    "    data[size] = []\n",
    "    for task in tasks:\n",
    "        base_results = results.loc[results[\"Size\"] == size]\n",
    "        base_results = base_results.loc[base_results[\"Task\"] == task]\n",
    "        base_results = base_results.loc[base_results[\"Model\"] == 'gpt4']\n",
    "        \n",
    "        io_results = base_results.loc[base_results[\"Method\"] == 'io']\n",
    "        io_results_mean = io_results['Cost'].values\n",
    "        \n",
    "        subresults = base_results.loc[base_results[\"Method\"] == 'ours']\n",
    "        subresults_mean = subresults['Cost'].values\n",
    "        \n",
    "        imrovement = abs(subresults_mean - io_results_mean)/subresults_mean\n",
    "        imrovement = round(100*imrovement.mean(), 2)\n",
    "        if imrovement >= 100:\n",
    "            imrovement = round(imrovement, 1)\n",
    "        data[size].append(imrovement)\n",
    "\n",
    "x = np.arange(len(tasks)) \n",
    "width = 0.15  # the width of the bars\n",
    "multiplier = 0\n",
    "\n",
    "fig, ax = plt.subplots(layout='constrained')\n",
    "fig.set_size_inches(18.5, 8)\n",
    "for size, improvement in data.items():\n",
    "    offset = width * multiplier\n",
    "    rects = ax.bar(x + offset, improvement, width, label=size)\n",
    "    ax.bar_label(rects, fmt='%.0f', fontsize=18)\n",
    "    multiplier += 1\n",
    "tasks_full = [\"Assign\", \"Knapsack\", \"Bin Pack\", \"TSP\", \"VRP\", \"JSP\"]\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Performance Improvement',fontsize = 35)\n",
    "ax.set_title('Problem Size Effect',fontsize = 35)\n",
    "ax.set_xticks(x + 2*width, tasks_full,fontsize = 30)\n",
    "ax.legend(loc='upper right', ncol=7, fontsize = 28)\n",
    "ax.set_ylim(35, 105)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1a5f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 3\n",
    "data = {}\n",
    "for model in ['gpt4', 'gemini', 'gpt3.5', 'llama70', 'llama7']: \n",
    "    data[model] = []\n",
    "    for task in tasks:\n",
    "        base_results = results.loc[results[\"Task\"] == task]\n",
    "        base_results = base_results.loc[base_results[\"Model\"] == model]\n",
    "\n",
    "        io_results = base_results.loc[base_results[\"Method\"] == 'io']\n",
    "        io_results_mean = io_results['Cost'].values\n",
    "\n",
    "        subresults = base_results.loc[base_results[\"Method\"] == 'ours']\n",
    "        subresults_mean = subresults['Cost'].values\n",
    "\n",
    "        imrovement = 100*abs(subresults_mean - io_results_mean)/subresults_mean\n",
    "        imrovement = round(imrovement.mean(), 2)\n",
    "        if imrovement >= 100:\n",
    "            imrovement = round(imrovement, 1)\n",
    "        data[model].append(imrovement)\n",
    "\n",
    "x = np.arange(len(tasks)) \n",
    "width = 0.15  # the width of the bars\n",
    "multiplier = 0\n",
    "\n",
    "fig, ax = plt.subplots(layout='constrained')\n",
    "fig.set_size_inches(18.5, 8)\n",
    "model_name = {\n",
    "    'gpt4' : 'GPT-4',\n",
    "    'gemini' : 'Gemini-1.5',\n",
    "    'gpt3.5' : 'GPT-3.5',\n",
    "    'llama7' : 'Llama-2-7b',\n",
    "    'llama70' : 'Llama-2-70b'\n",
    "}\n",
    "\n",
    "for model, improvement in data.items():\n",
    "    offset = width * multiplier\n",
    "    rects = ax.bar(x + offset, improvement, width, label=model_name[model])\n",
    "    ax.bar_label(rects, fmt='%.0f', fontsize=18)\n",
    "    multiplier += 1\n",
    "tasks_full = [\"Assign\", \"Knapsack\", \"Bin Pack\", \"TSP\", \"VRP\", \"JSP\"]\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Performance Improvement',fontsize = 35)\n",
    "ax.set_title('Model Effect',fontsize = 35)\n",
    "ax.set_xticks(x + 2*width, tasks_full,fontsize = 30)\n",
    "ax.legend(loc='upper right', ncol=7, fontsize = 25)\n",
    "ax.set_ylim(0, 95)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
