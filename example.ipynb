{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\77052\\anaconda3\\envs\\kcl_nlp\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "from models import *\n",
    "from data_processing2 import *\n",
    "from method import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"GOOGLE_API_KEY\"] = \"\" \n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"openai\" \n",
    "model_name = \"gpt-4-turbo-preview\"\n",
    "model = llm_function(model_type, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CP TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Problem:  You are given a list of customers with coordinates: (1): (87, 39); (2): (1, 90); (3): (28, 65); (4): (85, 85); (5): (50, 50); (6): (87, 39); (7): (1, 90); (8): (28, 65); (9): (85, 85); (10): (50, 50); (11): (87, 39); (12): (1, 90); (13): (28, 65); (14): (85, 85); (15): (50, 50); (16): (87, 39); (17): (1, 90); (18): (28, 65); (19): (85, 85); (20): (50, 50); (21): (87, 39); (22): (1, 90); (23): (28, 65); (24): (85, 85); (25): (50, 50); (26): (87, 39); (27): (1, 90); (28): (28, 65); (29): (85, 85); (30): (50, 50); (31): (87, 39); (32): (1, 90); (33): (28, 65); (34): (85, 85); (35): (50, 50); (36): (87, 39); (37): (1, 90); (38): (28, 65); (39): (85, 85); (40): (50, 50); (41): (87, 39); (42): (1, 90); (43): (28, 65); (44): (85, 85); (45): (50, 50); (46): (87, 39); (47): (1, 90); (48): (28, 65); (49): (85, 85); (50): (50, 50); (51): (87, 39); (52): (1, 90); (53): (28, 65); (54): (85, 85); (55): (50, 50); (56): (87, 39); (57): (1, 90); (58): (28, 65); (59): (85, 85); (60): (50, 50); (61): (87, 39); (62): (1, 90); (63): (28, 65); (64): (85, 85); (65): (50, 50); (66): (87, 39); (67): (1, 90); (68): (28, 65); (69): (85, 85); (70): (50, 50); (71): (87, 39); (72): (1, 90); (73): (28, 65); (74): (85, 85); (75): (50, 50); (76): (87, 39); (77): (1, 90); (78): (28, 65); (79): (85, 85); (80): (50, 50); (81): (87, 39); (82): (1, 90); (83): (28, 65); (84): (85, 85); (85): (50, 50); (86): (87, 39); (87): (1, 90); (88): (28, 65); (89): (85, 85); (90): (50, 50); (91): (87, 39); (92): (1, 90); (93): (28, 65); (94): (85, 85); (95): (50, 50); (96): (87, 39); (97): (1, 90); (98): (28, 65); (99): (85, 85); and a list of customer demands: (1): 12; (2): 8; (3): 16; (4): 5; (5): 0; (6): 12; (7): 8; (8): 16; (9): 5; (10): 0; (11): 12; (12): 8; (13): 16; (14): 5; (15): 0; (16): 12; (17): 8; (18): 16; (19): 5; (20): 0; (21): 12; (22): 8; (23): 16; (24): 5; (25): 0; (26): 12; (27): 8; (28): 16; (29): 5; (30): 0; (31): 12; (32): 8; (33): 16; (34): 5; (35): 0; (36): 12; (37): 8; (38): 16; (39): 5; (40): 0; (41): 12; (42): 8; (43): 16; (44): 5; (45): 0; (46): 12; (47): 8; (48): 16; (49): 5; (50): 0; (51): 12; (52): 8; (53): 16; (54): 5; (55): 0; (56): 12; (57): 8; (58): 16; (59): 5; (60): 0; (61): 12; (62): 8; (63): 16; (64): 5; (65): 0; (66): 12; (67): 8; (68): 16; (69): 5; (70): 0; (71): 12; (72): 8; (73): 16; (74): 5; (75): 0; (76): 12; (77): 8; (78): 16; (79): 5; (80): 0; (81): 12; (82): 8; (83): 16; (84): 5; (85): 0; (86): 12; (87): 8; (88): 16; (89): 5; (90): 0; (91): 12; (92): 8; (93): 16; (94): 5; (95): 0; (96): 12; (97): 8; (98): 16; (99): 5;. There is a depot (Customer 0) with coordinates (50, 50) and a vehicle with a maximum capacity of 50. The goal is to find the route that has the minimum total length and go through all the customers, starting and ending at the depot. \n",
      "\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"The requested model 'gpt-4o' cannot be used with the Assistants API in v1. Follow the migration guide to upgrade to v2: https://platform.openai.com/docs/assistants/migration.\", 'type': 'invalid_request_error', 'param': 'model', 'code': 'unsupported_model'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2272\\3845762314.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0minp_vrp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mor_task_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_prompt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Input Problem: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp_vrp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfast_SGE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp_vrp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0msolution\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_cp_solution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mor_task_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_cities\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Solution: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolution\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\77052\\Desktop\\projects\\MBZUAI\\KCL\\LLM-for-CP\\method.py\u001b[0m in \u001b[0;36mfast_SGE\u001b[1;34m(Q, f)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mfinal_thoughts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mcurrent_prompt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mQ\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mz_explore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mQ_N\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_prompt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[0mQ_N\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseparate_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ_N\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Methods to solve: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQ_N\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\77052\\Desktop\\projects\\MBZUAI\\KCL\\LLM-for-CP\\models.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, inp)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"openai\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_openai_ci_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"google\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_google_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\77052\\Desktop\\projects\\MBZUAI\\KCL\\LLM-for-CP\\models.py\u001b[0m in \u001b[0;36mpredict_openai_ci_model\u001b[1;34m(model_name, inp)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m### Code Interpreter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mclient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     assistant = client.beta.assistants.create(\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Math Tutor\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0minstructions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"You are a problem solver. Write and run code to answer questions if needed.\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\77052\\anaconda3\\envs\\kcl_nlp\\lib\\site-packages\\openai\\resources\\beta\\assistants\\assistants.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, model, description, file_ids, instructions, metadata, name, tools, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m    107\u001b[0m         \u001b[0mextra_headers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"OpenAI-Beta\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"assistants=v1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextra_headers\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m         return self._post(\n\u001b[0m\u001b[0;32m    109\u001b[0m             \u001b[1;34m\"/assistants\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m             body=maybe_transform(\n",
      "\u001b[1;32mc:\\Users\\77052\\anaconda3\\envs\\kcl_nlp\\lib\\site-packages\\openai\\_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1198\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"post\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1199\u001b[0m         )\n\u001b[1;32m-> 1200\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m     def patch(\n",
      "\u001b[1;32mc:\\Users\\77052\\anaconda3\\envs\\kcl_nlp\\lib\\site-packages\\openai\\_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    887\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[1;32m--> 889\u001b[1;33m         return self._request(\n\u001b[0m\u001b[0;32m    890\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m             \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\77052\\anaconda3\\envs\\kcl_nlp\\lib\\site-packages\\openai\\_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m             \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Re-raising status error\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 980\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    981\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    982\u001b[0m         return self._process_response(\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"The requested model 'gpt-4o' cannot be used with the Assistants API in v1. Follow the migration guide to upgrade to v2: https://platform.openai.com/docs/assistants/migration.\", 'type': 'invalid_request_error', 'param': 'model', 'code': 'unsupported_model'}}"
     ]
    }
   ],
   "source": [
    "or_task_name = \"vrp\"\n",
    "max_interval = 100\n",
    "num_cities = 99\n",
    "num_vehicles = 1\n",
    "capacity = 50\n",
    "or_task_obj = VRP(max_interval, num_cities, num_vehicles, capacity)\n",
    "coords = np.array([\n",
    "    [50,50],\n",
    "    [87,39],\n",
    "    [1, 90],\n",
    "    [28,65],\n",
    "    [85,85]\n",
    "                   ]*20)\n",
    "demands = np.array([0, 12, 8, 16, 5]*20)\n",
    "or_task_obj.variables = {\n",
    "                        'coords' : coords, \n",
    "                        'demands' : demands, \n",
    "                        'capacity' : capacity\n",
    "                        }\n",
    "inp_vrp = or_task_obj.create_prompt()\n",
    "print('Input Problem: ', inp_vrp, '\\n')\n",
    "out = fast_SGE(inp_vrp, model)\n",
    "solution = get_cp_solution(out, or_task_name, num_cities)\n",
    "print('Solution: ', solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GSM TASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_task_name = \"gsm8k\"\n",
    "tasks, answers = get_huggingface_dataset(huggingface_task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Problem:  A robe takes 2 bolts of blue fiber and half that much white fiber.  How many bolts in total does it take? \n",
      "\n",
      "Correct Answer:  It takes 2/2=<<2/2=1>>1 bolt of white fiber\n",
      "So the total amount of fabric is 2+1=<<2+1=3>>3 bolts of fabric\n",
      "#### 3 \n",
      "\n",
      "Methods to solve:  ['To solve this problem, several heuristic methods can be employed. Each method can help break down or simplify the process of finding the solution. Here are some heuristic methods that can be applied:', '', '- Break the problem into smaller parts', '- Use analogy', '- Simplify the problem', '- Work backwards', '- Make an educated guess or use estimation', '- Draw a diagram or use visual aids', '- Use systematic trial and error'] \n",
      "\n",
      "Solution:  3\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "inp = tasks[i]\n",
    "print('Input Problem: ', inp, '\\n')\n",
    "correct_out = answers[i]\n",
    "print('Correct Answer: ', correct_out, '\\n')\n",
    "out = fast_SGE(inp, model)\n",
    "solution = get_classical_solution(out)\n",
    "print('Solution: ', solution)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kcl_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
